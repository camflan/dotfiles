{
  "$schema": "https://charm.land/crush.json",
  "lsp": {
    "elixirls": {
      "command": "elixir-ls"
    },
    "typescript": {
      "command": "typescript-language-server",
      "args": ["--stdio"]
    },
    "vtsls": {
      "command": "vtsls",
      "args": ["--stdio"]
    }
  },
  "providers": {
    "jan": {
      "name": "Jan",
      "base_url": "http://localhost:1337/v1/",
      "type": "openai",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen3:30b",
          "context_window": 256000,
          "default_max_tokens": 20000,
          "supports_attachments": true,
          "has_reasoning_efforts": true,
          "can_reason": true,
          "cost_per_1m_in": 0,
          "cost_per_1m_out": 0,
          "cost_per_1m_in_cached": 0,
          "cost_per_1m_out_cached": 0
        },
        {
          "name": "GPT OSS 20B",
          "id": "gpt-oss:20b",
          "context_window": 12500,
          "default_max_tokens": 20000,
          "supports_attachments": true,
          "has_reasoning_efforts": true,
          "can_reason": true,
          "cost_per_1m_in": 0,
          "cost_per_1m_out": 0,
          "cost_per_1m_in_cached": 0,
          "cost_per_1m_out_cached": 0
        }
      ]
    },
    "ollama": {
      "name": "Ollama",
      "base_url": "http://localhost:11434/v1/",
      "type": "openai",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen3:30b",
          "context_window": 256000,
          "default_max_tokens": 20000,
          "supports_attachments": true,
          "has_reasoning_efforts": true,
          "can_reason": true,
          "cost_per_1m_in": 0,
          "cost_per_1m_out": 0,
          "cost_per_1m_in_cached": 0,
          "cost_per_1m_out_cached": 0
        }
      ]
    }
  }
}
